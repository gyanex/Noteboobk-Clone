Object.defineProperty(exports, '__esModule', { value: true });

var env = require('@llamaindex/env');
var index_cjs$3 = require('../../../tools/dist/index.cjs');
require('magic-bytes.js');
var index_cjs$2 = require('../../../zod/dist/index.cjs');
var index_cjs = require('../../../global/dist/index.cjs');
require('../../../schema/dist/index.cjs');
var index_cjs$1 = require('../../../utils/dist/index.cjs');

/**
 * Extracts just the text whether from
 *  a multi-modal message
 *  a single text message
 *  or a query
 *
 * @param message The message to extract text from.
 * @returns The extracted text
 */ function extractText(message) {
    if (typeof message === "object" && "query" in message) {
        return extractText(message.query);
    }
    if (typeof message !== "string" && !Array.isArray(message)) {
        console.warn("extractText called with non-MessageContent message, this is likely a bug.");
        return `${message}`;
    } else if (typeof message !== "string" && Array.isArray(message)) {
        // message is of type MessageContentDetail[] - retrieve just the text parts and concatenate them
        // so we can pass them to the context generator
        return message.filter((c)=>c.type === "text").map((c)=>c.text).join("\n\n");
    } else {
        return message;
    }
}

async function* streamConverter(stream, converter) {
    for await (const data of stream){
        const newData = converter(data);
        if (newData === null) {
            return;
        }
        yield newData;
    }
}

async function callTool(tool, toolCall, logger) {
    let input;
    if (typeof toolCall.input === "string") {
        try {
            input = JSON.parse(toolCall.input);
        } catch (e) {
            const output = `Tool ${toolCall.name} can't be called. Input is not a valid JSON object.`;
            logger.error(`${output} Try increasing the maxTokens parameter of your LLM. Invalid Input: ${toolCall.input}`);
            return {
                tool,
                input: {},
                output,
                isError: true
            };
        }
    } else {
        input = toolCall.input;
    }
    if (!tool) {
        logger.error(`Tool ${toolCall.name} does not exist.`);
        const output = `Tool ${toolCall.name} does not exist.`;
        return {
            tool,
            input,
            output,
            isError: true
        };
    }
    const call = tool.call;
    let output;
    if (!call) {
        logger.error(`Tool ${tool.metadata.name} (remote:${toolCall.name}) does not have a implementation.`);
        output = `Tool ${tool.metadata.name} (remote:${toolCall.name}) does not have a implementation.`;
        return {
            tool,
            input,
            output,
            isError: true
        };
    }
    try {
        index_cjs.Settings.callbackManager.dispatchEvent("llm-tool-call", {
            toolCall: {
                ...toolCall,
                input
            }
        });
        output = await call.call(tool, input);
        logger.log(`Tool ${tool.metadata.name} (remote:${toolCall.name}) succeeded.`);
        logger.log(`Output: ${JSON.stringify(output)}`);
        index_cjs$1.assertIsJSONValue(output);
        const toolOutput = {
            tool,
            input,
            output,
            isError: false
        };
        index_cjs.Settings.callbackManager.dispatchEvent("llm-tool-result", {
            toolCall: {
                ...toolCall,
                input
            },
            toolResult: {
                ...toolOutput
            }
        });
        return toolOutput;
    } catch (e) {
        output = index_cjs$1.prettifyError(e);
        logger.error(`Tool ${tool.metadata.name} (remote:${toolCall.name}) failed: ${output}`);
    }
    return {
        tool,
        input,
        output,
        isError: true
    };
}

const getToolCallsFromResponse = (response)=>{
    let options;
    if ("message" in response) {
        options = response.message.options;
    } else {
        options = response.options;
    }
    if (options && "toolCall" in options) {
        return options.toolCall.map((toolCall)=>({
                ...toolCall,
                input: // XXX: this is a hack openai returns parsed object for streaming, but not for
                // non-streaming
                typeof toolCall.input === "string" ? JSON.parse(toolCall.input) : toolCall.input
            }));
    }
    return [];
};
const callToolToMessage = async (tools, toolCall, logger)=>{
    const tool = tools?.find((t)=>t.metadata.name === toolCall.name);
    const toolOutput = await callTool(tool, toolCall, logger);
    return {
        role: "user",
        content: index_cjs$1.stringifyJSONToMessageContent(toolOutput.output),
        options: {
            toolResult: {
                id: toolCall.id,
                name: toolCall.name,
                result: toolOutput.output,
                isError: toolOutput.isError
            }
        }
    };
};

const STRUCTURED_OUTPUT_TOOL_NAME = "format_output";
class BaseLLM {
    async complete(params) {
        const { prompt, stream, responseFormat } = params;
        if (stream) {
            const stream = await this.chat({
                messages: [
                    {
                        content: prompt,
                        role: "user"
                    }
                ],
                stream: true,
                ...responseFormat ? {
                    responseFormat
                } : {}
            });
            return streamConverter(stream, (chunk)=>{
                return {
                    raw: null,
                    text: chunk.delta
                };
            });
        }
        const chatResponse = await this.chat({
            messages: [
                {
                    content: prompt,
                    role: "user"
                }
            ],
            ...responseFormat ? {
                responseFormat
            } : {}
        });
        return {
            text: extractText(chatResponse.message.content),
            raw: chatResponse.raw
        };
    }
    async exec(params) {
        const responseFormat = params.responseFormat;
        if (typeof responseFormat != "undefined" && index_cjs$2.isZodSchema(responseFormat)) {
            const structuredTool = index_cjs$3.tool({
                name: STRUCTURED_OUTPUT_TOOL_NAME,
                description: "Respond with a JSON object",
                parameters: responseFormat,
                execute: (args)=>{
                    const result = index_cjs$2.safeParseSchema(responseFormat, args);
                    if (!result.success) {
                        console.error("Invalid input from LLM:", result.error);
                        return JSON.stringify({
                            error: "Invalid schema",
                            details: result.error
                        });
                    }
                    return result.data;
                }
            });
            if (Array.isArray(params.tools)) {
                params.tools.push(structuredTool);
            } else {
                params.tools = [
                    structuredTool
                ];
            }
            params.responseFormat = undefined;
        }
        if (params.stream) {
            return this.streamExec(params);
        }
        const logger = params.logger ?? env.emptyLogger;
        const newMessages = [];
        const response = await this.chat(params);
        newMessages.push(response.message);
        const toolCalls = getToolCallsFromResponse(response);
        let structuredOutput = undefined;
        if (params.tools && toolCalls.length > 0) {
            for (const toolCall of toolCalls){
                const toolResultMessage = await callToolToMessage(params.tools, toolCall, logger);
                if (toolResultMessage) {
                    newMessages.push(toolResultMessage);
                }
                if (toolCall.name === STRUCTURED_OUTPUT_TOOL_NAME) {
                    structuredOutput = toolResultMessage?.options?.toolResult?.result;
                }
            }
        }
        return {
            newMessages,
            toolCalls,
            object: structuredOutput
        };
    }
    async streamExec(params) {
        const logger = params.logger ?? env.emptyLogger;
        const responseStream = await this.chat(params);
        const iterator = responseStream[Symbol.asyncIterator]();
        const first = await iterator.next();
        // Set firstChunk to null if empty
        const firstChunk = !first.done ? first.value : null;
        const hasToolCallsInFirst = firstChunk?.options && "toolCall" in firstChunk.options;
        if (!hasToolCallsInFirst) {
            // extract structured output from the last message
            const lastMessage = params.messages[params.messages.length - 1];
            const toolResult = lastMessage?.options?.toolResult;
            const structuredOutput = toolResult?.name === STRUCTURED_OUTPUT_TOOL_NAME ? toolResult.result : undefined;
            let content = firstChunk?.delta ?? "";
            let finished = false;
            return {
                stream: async function*() {
                    if (firstChunk) {
                        yield firstChunk;
                    }
                    for await (const chunk of {
                        [Symbol.asyncIterator]: ()=>iterator
                    }){
                        content += chunk.delta;
                        yield chunk;
                    }
                    finished = true;
                }(),
                toolCalls: [],
                newMessages () {
                    if (!finished) {
                        throw new Error("New messages are not ready yet. Call newMessages() after the stream is done.");
                    }
                    return content ? [
                        {
                            role: "assistant",
                            content
                        }
                    ] : [];
                },
                object: structuredOutput
            };
        }
        // Helper function to process a chunk
        function processChunk(chunk, toolCallMap) {
            if (chunk.options && "toolCall" in chunk.options) {
                // update tool call map
                for (const toolCall of chunk.options.toolCall){
                    if (toolCall.id) {
                        toolCallMap.set(toolCall.id, toolCall);
                    }
                }
                // return the current full response with the tool calls
                const toolCalls = Array.from(toolCallMap.values());
                return {
                    ...chunk,
                    options: {
                        ...chunk.options,
                        toolCall: toolCalls
                    }
                };
            }
            return null;
        }
        // Collect for tool call
        let fullResponse = null;
        const toolCallMap = new Map();
        // Process first chunk
        fullResponse = processChunk(firstChunk, toolCallMap);
        // Process remaining chunks
        while(true){
            const next = await iterator.next();
            if (next.done) break;
            const chunk = next.value;
            const potentialFull = processChunk(chunk, toolCallMap);
            if (potentialFull) {
                fullResponse = potentialFull;
            }
        }
        if (params.tools && fullResponse) {
            const toolCalls = getToolCallsFromResponse(fullResponse);
            const messages = [];
            messages.push({
                role: "assistant",
                content: "",
                options: {
                    toolCall: toolCalls
                }
            });
            let structuredOutput = undefined;
            for (const toolCall of toolCalls){
                const toolResultMessage = await callToolToMessage(params.tools, toolCall, logger);
                if (toolResultMessage) {
                    messages.push(toolResultMessage);
                }
                if (toolCall.name === STRUCTURED_OUTPUT_TOOL_NAME) {
                    structuredOutput = toolResultMessage?.options?.toolResult?.result;
                }
            }
            return {
                stream: async function*() {}(),
                newMessages () {
                    return messages;
                },
                toolCalls,
                object: structuredOutput
            };
        } else {
            throw new Error("Cannot get tool calls from response");
        }
    }
}
class ToolCallLLM extends BaseLLM {
}

class MockLLM extends ToolCallLLM {
    constructor(options){
        super(), this.supportToolCall = true;
        this.options = {
            timeBetweenToken: options?.timeBetweenToken ?? 20,
            responseMessage: options?.responseMessage ?? "This is a mock response",
            ...options?.mockToolCallResponse && {
                mockToolCallResponse: options.mockToolCallResponse
            }
        };
        this.metadata = options?.metadata ?? {
            model: "MockLLM",
            temperature: 0.5,
            topP: 0.5,
            contextWindow: 1024,
            tokenizer: undefined,
            structuredOutput: true
        };
    }
    async chat(params) {
        const responseMessage = this.options.responseMessage;
        const timeBetweenToken = this.options.timeBetweenToken;
        const mockToolCallResponse = this.options.mockToolCallResponse;
        // Check if we have tools and should simulate tool calls
        const shouldSimulateToolCalls = params.tools && mockToolCallResponse;
        if (params.stream) {
            if (shouldSimulateToolCalls) {
                return async function*() {
                    // First yield the tool call
                    yield {
                        delta: "",
                        raw: {},
                        options: {
                            toolCall: mockToolCallResponse.toolCalls
                        }
                    };
                }();
            } else {
                return async function*() {
                    for (const char of responseMessage){
                        yield {
                            delta: char,
                            raw: {}
                        };
                        await new Promise((resolve)=>setTimeout(resolve, timeBetweenToken));
                    }
                }();
            }
        }
        if (shouldSimulateToolCalls) {
            return {
                message: {
                    content: mockToolCallResponse.responseMessage || "",
                    role: "assistant",
                    options: {
                        toolCall: mockToolCallResponse.toolCalls
                    }
                },
                raw: {}
            };
        }
        return {
            message: {
                content: responseMessage,
                role: "assistant"
            },
            raw: {}
        };
    }
    async complete(params) {
        const responseMessage = this.options.responseMessage;
        const timeBetweenToken = this.options.timeBetweenToken;
        if (params.stream) {
            return async function*() {
                for (const char of responseMessage){
                    yield {
                        delta: char,
                        text: char,
                        raw: {}
                    };
                    await new Promise((resolve)=>setTimeout(resolve, timeBetweenToken));
                }
            }();
        }
        return {
            text: responseMessage,
            raw: {}
        };
    }
}

exports.MockLLM = MockLLM;
