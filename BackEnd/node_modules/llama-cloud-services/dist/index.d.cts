import { BaseNodePostprocessor } from '@llamaindex/core/postprocessor';
import { QueryBundle, BaseQueryEngine } from '@llamaindex/core/query-engine';
import { BaseSynthesizer } from '@llamaindex/core/response-synthesizers';
import { NodeWithScore, Document } from '@llamaindex/core/schema';
import { RetrievalParams, MetadataFilters as MetadataFilters$1, PipelineCreateReadable } from '../api/dist/index.cjs';
import { BaseRetriever } from '@llamaindex/core/retriever';
import { ToolMetadata, BaseTool } from '@llamaindex/core/llms';
export { LlamaParseReader } from '../reader/dist/index.cjs';
import { Client } from '@hey-api/client-fetch';
import { File as File$1 } from 'buffer';
import { ExtractConfig, ExtractAgent } from '../extract/dist/index.cjs';
export { ExtractConfig } from '../extract/dist/index.cjs';
import { ClassifierRule, ClassifyParsingConfiguration, ClassifyJobResults } from '../classify/dist/index.cjs';
export { ClassifierRule, ClassifyJobResults, ClassifyParsingConfiguration } from '../classify/dist/index.cjs';

type AdvancedModeTransformConfig = {
    mode?: "advanced";
    /**
     * Configuration for the segmentation.
     */
    segmentation_config?: NoneSegmentationConfig | PageSegmentationConfig | ElementSegmentationConfig;
    /**
     * Configuration for the chunking.
     */
    chunking_config?: NoneChunkingConfig | CharacterChunkingConfig | TokenChunkingConfig | SentenceChunkingConfig | SemanticChunkingConfig;
};
type AutoTransformConfig = {
    mode?: "auto";
    /**
     * Chunk size for the transformation.
     */
    chunk_size?: number;
    /**
     * Chunk overlap for the transformation.
     */
    chunk_overlap?: number;
};
type AzureOpenAiEmbedding = {
    /**
     * The name of the OpenAI embedding model.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * Additional kwargs for the OpenAI API.
     */
    additional_kwargs?: {
        [key: string]: unknown;
    };
    /**
     * The OpenAI API key.
     */
    api_key?: string | null;
    /**
     * The base URL for Azure deployment.
     */
    api_base?: string;
    /**
     * The version for Azure OpenAI API.
     */
    api_version?: string;
    /**
     * Maximum number of retries.
     */
    max_retries?: number;
    /**
     * Timeout for each request.
     */
    timeout?: number;
    /**
     * The default headers for API requests.
     */
    default_headers?: {
        [key: string]: string;
    } | null;
    /**
     * Reuse the OpenAI client between requests. When doing anything with large volumes of async API calls, setting this to false can improve stability.
     */
    reuse_client?: boolean;
    /**
     * The number of dimensions on the output embedding vectors. Works only with v3 embedding models.
     */
    dimensions?: number | null;
    /**
     * The Azure endpoint to use.
     */
    azure_endpoint?: string | null;
    /**
     * The Azure deployment to use.
     */
    azure_deployment?: string | null;
    class_name?: string;
};
type AzureOpenAiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "AZURE_EMBEDDING";
    /**
     * Configuration for the Azure OpenAI embedding model.
     */
    component?: AzureOpenAiEmbedding;
};
type BedrockEmbedding = {
    /**
     * The modelId of the Bedrock model to use.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * The name of aws profile to use. If not given, then the default profile is used.
     */
    profile_name?: string | null;
    /**
     * AWS Access Key ID to use
     */
    aws_access_key_id?: string | null;
    /**
     * AWS Secret Access Key to use
     */
    aws_secret_access_key?: string | null;
    /**
     * AWS Session Token to use
     */
    aws_session_token?: string | null;
    /**
     * AWS region name to use. Uses region configured in AWS CLI if not passed
     */
    region_name?: string | null;
    /**
     * The maximum number of API retries.
     */
    max_retries?: number;
    /**
     * The timeout for the Bedrock API request in seconds. It will be used for both connect and read timeouts.
     */
    timeout?: number;
    /**
     * Additional kwargs for the bedrock client.
     */
    additional_kwargs?: {
        [key: string]: unknown;
    };
    class_name?: string;
};
type BedrockEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "BEDROCK_EMBEDDING";
    /**
     * Configuration for the Bedrock embedding model.
     */
    component?: BedrockEmbedding;
};
type CharacterChunkingConfig = {
    chunk_size?: number;
    chunk_overlap?: number;
    mode?: "character";
};
/**
 * Cloud AstraDB Vector Store.
 *
 * This class is used to store the configuration for an AstraDB vector store, so that it can be
 * created and used in LlamaCloud.
 *
 * Args:
 * token (str): The Astra DB Application Token to use.
 * api_endpoint (str): The Astra DB JSON API endpoint for your database.
 * collection_name (str): Collection name to use. If not existing, it will be created.
 * embedding_dimension (int): Length of the embedding vectors in use.
 * keyspace (optional[str]): The keyspace to use. If not provided, 'default_keyspace'
 */
type CloudAstraDbVectorStoreReadable = {
    supports_nested_metadata_filters?: true;
    /**
     * The Astra DB JSON API endpoint for your database
     */
    api_endpoint: string;
    /**
     * Collection name to use. If not existing, it will be created
     */
    collection_name: string;
    /**
     * Length of the embedding vectors in use
     */
    embedding_dimension: number;
    /**
     * The keyspace to use. If not provided, 'default_keyspace'
     */
    keyspace?: string | null;
    class_name?: string;
};
/**
 * Cloud Azure AI Search Vector Store.
 */
type CloudAzureAiSearchVectorStoreReadable = {
    supports_nested_metadata_filters?: true;
    search_service_endpoint: string;
    search_service_api_version?: string | null;
    index_name?: string | null;
    filterable_metadata_field_keys?: {
        [key: string]: unknown;
    } | null;
    embedding_dimension?: number | null;
    client_id?: string | null;
    client_secret?: string | null;
    tenant_id?: string | null;
    class_name?: string;
};
/**
 * Cloud Milvus Vector Store.
 */
type CloudMilvusVectorStoreReadable = {
    supports_nested_metadata_filters?: boolean;
    uri: string;
    collection_name?: string | null;
    token?: string | null;
    embedding_dimension?: number | null;
    class_name?: string;
};
/**
 * Cloud MongoDB Atlas Vector Store.
 *
 * This class is used to store the configuration for a MongoDB Atlas vector store,
 * so that it can be created and used in LlamaCloud.
 *
 * Args:
 * mongodb_uri (str): URI for connecting to MongoDB Atlas
 * db_name (str): name of the MongoDB database
 * collection_name (str): name of the MongoDB collection
 * vector_index_name (str): name of the MongoDB Atlas vector index
 * fulltext_index_name (str): name of the MongoDB Atlas full-text index
 */
type CloudMongoDbAtlasVectorSearchReadable = {
    supports_nested_metadata_filters?: boolean;
    db_name: string;
    collection_name: string;
    vector_index_name?: string | null;
    fulltext_index_name?: string | null;
    embedding_dimension?: number | null;
    class_name?: string;
};
/**
 * Cloud Pinecone Vector Store.
 *
 * This class is used to store the configuration for a Pinecone vector store, so that it can be
 * created and used in LlamaCloud.
 *
 * Args:
 * api_key (str): API key for authenticating with Pinecone
 * index_name (str): name of the Pinecone index
 * namespace (optional[str]): namespace to use in the Pinecone index
 * insert_kwargs (optional[dict]): additional kwargs to pass during insertion
 */
type CloudPineconeVectorStoreReadable = {
    supports_nested_metadata_filters?: true;
    index_name: string;
    namespace?: string | null;
    insert_kwargs?: {
        [key: string]: unknown;
    } | null;
    class_name?: string;
};
type CloudPostgresVectorStoreReadable = {
    supports_nested_metadata_filters?: boolean;
    database: string;
    host: string;
    port: number;
    user: string;
    table_name: string;
    schema_name: string;
    embed_dim: number;
    hybrid_search?: boolean | null;
    perform_setup?: boolean;
    /**
     * HNSW settings for PGVector index. Set to null to disable HNSW indexing in favor of a brute force indexing/exact search strategy instead.
     */
    hnsw_settings?: PgVectorHnswSettings | null;
    class_name?: string;
};
/**
 * Cloud Qdrant Vector Store.
 *
 * This class is used to store the configuration for a Qdrant vector store, so that it can be
 * created and used in LlamaCloud.
 *
 * Args:
 * collection_name (str): name of the Qdrant collection
 * url (str): url of the Qdrant instance
 * api_key (str): API key for authenticating with Qdrant
 * max_retries (int): maximum number of retries in case of a failure. Defaults to 3
 * client_kwargs (dict): additional kwargs to pass to the Qdrant client
 */
type CloudQdrantVectorStoreReadable = {
    supports_nested_metadata_filters?: true;
    collection_name: string;
    url: string;
    max_retries?: number;
    client_kwargs?: {
        [key: string]: unknown;
    };
    class_name?: string;
};
type CohereEmbedding = {
    /**
     * The modelId of the Cohere model to use.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * The Cohere API key.
     */
    api_key: string | null;
    /**
     * Truncation type - START/ END/ NONE
     */
    truncate?: string;
    /**
     * Model Input type. If not provided, search_document and search_query are used when needed.
     */
    input_type?: string | null;
    /**
     * Embedding type. If not provided float embedding_type is used when needed.
     */
    embedding_type?: string;
    class_name?: string;
};
type CohereEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "COHERE_EMBEDDING";
    /**
     * Configuration for the Cohere embedding model.
     */
    component?: CohereEmbedding;
};
type ConfigurableDataSinkNames = "PINECONE" | "POSTGRES" | "QDRANT" | "AZUREAI_SEARCH" | "MONGODB_ATLAS" | "MILVUS" | "ASTRA_DB";
declare const ConfigurableDataSinkNames: {
    readonly PINECONE: "PINECONE";
    readonly POSTGRES: "POSTGRES";
    readonly QDRANT: "QDRANT";
    readonly AZUREAI_SEARCH: "AZUREAI_SEARCH";
    readonly MONGODB_ATLAS: "MONGODB_ATLAS";
    readonly MILVUS: "MILVUS";
    readonly ASTRA_DB: "ASTRA_DB";
};
/**
 * Schema for a data sink.
 */
type DataSinkReadable = {
    /**
     * Unique identifier
     */
    id: string;
    /**
     * Creation datetime
     */
    created_at?: string | null;
    /**
     * Update datetime
     */
    updated_at?: string | null;
    /**
     * The name of the data sink.
     */
    name: string;
    sink_type: ConfigurableDataSinkNames;
    /**
     * Component that implements the data sink
     */
    component: {
        [key: string]: unknown;
    } | CloudPineconeVectorStoreReadable | CloudPostgresVectorStoreReadable | CloudQdrantVectorStoreReadable | CloudAzureAiSearchVectorStoreReadable | CloudMongoDbAtlasVectorSearchReadable | CloudMilvusVectorStoreReadable | CloudAstraDbVectorStoreReadable;
    project_id: string;
};
type ElementSegmentationConfig = {
    mode?: "element";
};
/**
 * Schema for an embedding model config.
 */
type EmbeddingModelConfig = {
    /**
     * Unique identifier
     */
    id: string;
    /**
     * Creation datetime
     */
    created_at?: string | null;
    /**
     * Update datetime
     */
    updated_at?: string | null;
    /**
     * The name of the embedding model config.
     */
    name: string;
    /**
     * The embedding configuration for the embedding model config.
     */
    embedding_config: ({
        type: "AZURE_EMBEDDING";
    } & AzureOpenAiEmbeddingConfig) | ({
        type: "COHERE_EMBEDDING";
    } & CohereEmbeddingConfig) | ({
        type: "GEMINI_EMBEDDING";
    } & GeminiEmbeddingConfig) | ({
        type: "HUGGINGFACE_API_EMBEDDING";
    } & HuggingFaceInferenceApiEmbeddingConfig) | ({
        type: "OPENAI_EMBEDDING";
    } & OpenAiEmbeddingConfig) | ({
        type: "VERTEXAI_EMBEDDING";
    } & VertexAiEmbeddingConfig) | ({
        type: "BEDROCK_EMBEDDING";
    } & BedrockEmbeddingConfig);
    project_id: string;
};
/**
 * Schema for the params for an eval execution.
 */
type EvalExecutionParams = {
    /**
     * The LLM model to use within eval execution.
     */
    llm_model?: SupportedLlmModelNames;
    /**
     * The template to use for the question answering prompt.
     */
    qa_prompt_tmpl?: string;
};
/**
 * Enum for representing the different available page error handling modes
 */
type FailPageMode = "raw_text" | "blank_page" | "error_message";
/**
 * Enum for representing the different available page error handling modes
 */
declare const FailPageMode: {
    readonly RAW_TEXT: "raw_text";
    readonly BLANK_PAGE: "blank_page";
    readonly ERROR_MESSAGE: "error_message";
};
/**
 * Vector store filter conditions to combine different filters.
 */
type FilterCondition = "and" | "or" | "not";
/**
 * Vector store filter conditions to combine different filters.
 */
declare const FilterCondition: {
    readonly AND: "and";
    readonly OR: "or";
    readonly NOT: "not";
};
/**
 * Vector store filter operator.
 */
type FilterOperator = "==" | ">" | "<" | "!=" | ">=" | "<=" | "in" | "nin" | "any" | "all" | "text_match" | "text_match_insensitive" | "contains" | "is_empty";
/**
 * Vector store filter operator.
 */
declare const FilterOperator: {
    readonly "==": "==";
    readonly ">": ">";
    readonly "<": "<";
    readonly "!=": "!=";
    readonly ">=": ">=";
    readonly "<=": "<=";
    readonly IN: "in";
    readonly NIN: "nin";
    readonly ANY: "any";
    readonly ALL: "all";
    readonly TEXT_MATCH: "text_match";
    readonly TEXT_MATCH_INSENSITIVE: "text_match_insensitive";
    readonly CONTAINS: "contains";
    readonly IS_EMPTY: "is_empty";
};
type GeminiEmbedding = {
    /**
     * The modelId of the Gemini model to use.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * Title is only applicable for retrieval_document tasks, and is used to represent a document title. For other tasks, title is invalid.
     */
    title?: string | null;
    /**
     * The task for embedding model.
     */
    task_type?: string | null;
    /**
     * API key to access the model. Defaults to None.
     */
    api_key?: string | null;
    /**
     * API base to access the model. Defaults to None.
     */
    api_base?: string | null;
    /**
     * Transport to access the model. Defaults to None.
     */
    transport?: string | null;
    class_name?: string;
};
type GeminiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "GEMINI_EMBEDDING";
    /**
     * Configuration for the Gemini embedding model.
     */
    component?: GeminiEmbedding;
};
type HuggingFaceInferenceApiEmbedding = {
    /**
     * Hugging Face model name. If None, the task will be used.
     */
    model_name?: string | null;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * Pooling strategy. If None, the model's default pooling is used.
     */
    pooling?: Pooling | null;
    /**
     * Instruction to prepend during query embedding.
     */
    query_instruction?: string | null;
    /**
     * Instruction to prepend during text embedding.
     */
    text_instruction?: string | null;
    /**
     * Hugging Face token. Will default to the locally saved token. Pass token=False if you donâ€™t want to send your token to the server.
     */
    token?: string | boolean | null;
    /**
     * The maximum number of seconds to wait for a response from the server. Loading a new model in Inference API can take up to several minutes. Defaults to None, meaning it will loop until the server is available.
     */
    timeout?: number | null;
    /**
     * Additional headers to send to the server. By default only the authorization and user-agent headers are sent. Values in this dictionary will override the default values.
     */
    headers?: {
        [key: string]: string;
    } | null;
    /**
     * Additional cookies to send to the server.
     */
    cookies?: {
        [key: string]: string;
    } | null;
    /**
     * Optional task to pick Hugging Face's recommended model, used when model_name is left as default of None.
     */
    task?: string | null;
    class_name?: string;
};
type HuggingFaceInferenceApiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "HUGGINGFACE_API_EMBEDDING";
    /**
     * Configuration for the HuggingFace Inference API embedding model.
     */
    component?: HuggingFaceInferenceApiEmbedding;
};
/**
 * Settings that can be configured for how to use LlamaParse to parse files within a LlamaCloud pipeline.
 */
type LlamaParseParameters = {
    /**
     * The outbound webhook configurations
     */
    webhook_configurations?: Array<WebhookConfiguration> | null;
    /**
     * The priority for the request. This field may be ignored or overwritten depending on the organization tier.
     */
    priority?: ("low" | "medium" | "high" | "critical") | null;
    languages?: Array<ParserLanguages>;
    parsing_instruction?: string | null;
    disable_ocr?: boolean | null;
    annotate_links?: boolean | null;
    adaptive_long_table?: boolean | null;
    compact_markdown_table?: boolean | null;
    disable_reconstruction?: boolean | null;
    disable_image_extraction?: boolean | null;
    invalidate_cache?: boolean | null;
    outlined_table_extraction?: boolean | null;
    merge_tables_across_pages_in_markdown?: boolean | null;
    output_pdf_of_document?: boolean | null;
    do_not_cache?: boolean | null;
    fast_mode?: boolean | null;
    skip_diagonal_text?: boolean | null;
    preserve_layout_alignment_across_pages?: boolean | null;
    preserve_very_small_text?: boolean | null;
    gpt4o_mode?: boolean | null;
    gpt4o_api_key?: string | null;
    do_not_unroll_columns?: boolean | null;
    extract_layout?: boolean | null;
    high_res_ocr?: boolean | null;
    html_make_all_elements_visible?: boolean | null;
    layout_aware?: boolean | null;
    specialized_chart_parsing_agentic?: boolean | null;
    specialized_chart_parsing_plus?: boolean | null;
    specialized_chart_parsing_efficient?: boolean | null;
    specialized_image_parsing?: boolean | null;
    precise_bounding_box?: boolean | null;
    html_remove_navigation_elements?: boolean | null;
    html_remove_fixed_elements?: boolean | null;
    guess_xlsx_sheet_name?: boolean | null;
    page_separator?: string | null;
    bounding_box?: string | null;
    bbox_top?: number | null;
    bbox_right?: number | null;
    bbox_bottom?: number | null;
    bbox_left?: number | null;
    target_pages?: string | null;
    use_vendor_multimodal_model?: boolean | null;
    vendor_multimodal_model_name?: string | null;
    model?: string | null;
    vendor_multimodal_api_key?: string | null;
    page_prefix?: string | null;
    page_suffix?: string | null;
    webhook_url?: string | null;
    preset?: string | null;
    take_screenshot?: boolean | null;
    is_formatting_instruction?: boolean | null;
    premium_mode?: boolean | null;
    continuous_mode?: boolean | null;
    input_s3_path?: string | null;
    input_s3_region?: string | null;
    output_s3_path_prefix?: string | null;
    output_s3_region?: string | null;
    project_id?: string | null;
    azure_openai_deployment_name?: string | null;
    azure_openai_endpoint?: string | null;
    azure_openai_api_version?: string | null;
    azure_openai_key?: string | null;
    input_url?: string | null;
    http_proxy?: string | null;
    auto_mode?: boolean | null;
    auto_mode_trigger_on_regexp_in_page?: string | null;
    auto_mode_trigger_on_text_in_page?: string | null;
    auto_mode_trigger_on_table_in_page?: boolean | null;
    auto_mode_trigger_on_image_in_page?: boolean | null;
    auto_mode_configuration_json?: string | null;
    structured_output?: boolean | null;
    structured_output_json_schema?: string | null;
    structured_output_json_schema_name?: string | null;
    max_pages?: number | null;
    max_pages_enforced?: number | null;
    extract_charts?: boolean | null;
    formatting_instruction?: string | null;
    complemental_formatting_instruction?: string | null;
    content_guideline_instruction?: string | null;
    spreadsheet_extract_sub_tables?: boolean | null;
    spreadsheet_force_formula_computation?: boolean | null;
    inline_images_in_markdown?: boolean | null;
    job_timeout_in_seconds?: number | null;
    job_timeout_extra_time_per_page_in_seconds?: number | null;
    strict_mode_image_extraction?: boolean | null;
    strict_mode_image_ocr?: boolean | null;
    strict_mode_reconstruction?: boolean | null;
    strict_mode_buggy_font?: boolean | null;
    save_images?: boolean | null;
    hide_headers?: boolean | null;
    hide_footers?: boolean | null;
    page_header_prefix?: string | null;
    page_header_suffix?: string | null;
    page_footer_prefix?: string | null;
    page_footer_suffix?: string | null;
    ignore_document_elements_for_layout_detection?: boolean | null;
    output_tables_as_HTML?: boolean | null;
    internal_is_screenshot_job?: boolean | null;
    parse_mode?: ParsingMode | null;
    system_prompt?: string | null;
    system_prompt_append?: string | null;
    user_prompt?: string | null;
    page_error_tolerance?: number | null;
    replace_failed_page_mode?: FailPageMode | null;
    replace_failed_page_with_error_message_prefix?: string | null;
    replace_failed_page_with_error_message_suffix?: string | null;
    markdown_table_multiline_header_separator?: string | null;
};
type ManagedOpenAiEmbedding = {
    /**
     * The name of the OpenAI embedding model.
     */
    model_name?: "openai-text-embedding-3-small";
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    class_name?: string;
};
type ManagedOpenAiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "MANAGED_OPENAI_EMBEDDING";
    /**
     * Configuration for the Managed OpenAI embedding model.
     */
    component?: ManagedOpenAiEmbedding;
};
/**
 * Comprehensive metadata filter for vector stores to support more operators.
 *
 * Value uses Strict types, as int, float and str are compatible types and were all
 * converted to string before.
 *
 * See: https://docs.pydantic.dev/latest/usage/types/#strict-types
 */
type MetadataFilter = {
    key: string;
    value: number | number | string | Array<string> | Array<number> | Array<number> | null;
    operator?: FilterOperator;
};
/**
 * Metadata filters for vector stores.
 */
type MetadataFilters = {
    filters: Array<MetadataFilter | MetadataFilters>;
    condition?: FilterCondition | null;
};
type NoneChunkingConfig = {
    mode?: "none";
};
type NoneSegmentationConfig = {
    mode?: "none";
};
type OpenAiEmbedding = {
    /**
     * The name of the OpenAI embedding model.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * Additional kwargs for the OpenAI API.
     */
    additional_kwargs?: {
        [key: string]: unknown;
    };
    /**
     * The OpenAI API key.
     */
    api_key?: string | null;
    /**
     * The base URL for OpenAI API.
     */
    api_base?: string | null;
    /**
     * The version for OpenAI API.
     */
    api_version?: string | null;
    /**
     * Maximum number of retries.
     */
    max_retries?: number;
    /**
     * Timeout for each request.
     */
    timeout?: number;
    /**
     * The default headers for API requests.
     */
    default_headers?: {
        [key: string]: string;
    } | null;
    /**
     * Reuse the OpenAI client between requests. When doing anything with large volumes of async API calls, setting this to false can improve stability.
     */
    reuse_client?: boolean;
    /**
     * The number of dimensions on the output embedding vectors. Works only with v3 embedding models.
     */
    dimensions?: number | null;
    class_name?: string;
};
type OpenAiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "OPENAI_EMBEDDING";
    /**
     * Configuration for the OpenAI embedding model.
     */
    component?: OpenAiEmbedding;
};
/**
 * Distance methods for PGVector.
 * Docs:
 * https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options
 */
type PgVectorDistanceMethod = "l2" | "ip" | "cosine" | "l1" | "hamming" | "jaccard";
/**
 * Distance methods for PGVector.
 * Docs:
 * https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options
 */
declare const PgVectorDistanceMethod: {
    readonly L2: "l2";
    readonly IP: "ip";
    readonly COSINE: "cosine";
    readonly L1: "l1";
    readonly HAMMING: "hamming";
    readonly JACCARD: "jaccard";
};
/**
 * HNSW settings for PGVector.
 */
type PgVectorHnswSettings = {
    /**
     * The number of edges to use during the construction phase.
     */
    ef_construction?: number;
    /**
     * The number of edges to use during the search phase.
     */
    ef_search?: number;
    /**
     * The number of bi-directional links created for each new element.
     */
    m?: number;
    /**
     * The type of vector to use.
     */
    vector_type?: PgVectorVectorType;
    /**
     * The distance method to use.
     */
    distance_method?: PgVectorDistanceMethod;
};
/**
 * Vector storage formats for PGVector.
 * Docs:
 * https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options
 */
type PgVectorVectorType = "vector" | "half_vec" | "bit" | "sparse_vec";
/**
 * Vector storage formats for PGVector.
 * Docs:
 * https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options
 */
declare const PgVectorVectorType: {
    readonly VECTOR: "vector";
    readonly HALF_VEC: "half_vec";
    readonly BIT: "bit";
    readonly SPARSE_VEC: "sparse_vec";
};
type PageSegmentationConfig = {
    mode?: "page";
    page_separator?: string;
};
/**
 * Enum for representing the languages supported by the parser
 */
type ParserLanguages = "af" | "az" | "bs" | "cs" | "cy" | "da" | "de" | "en" | "es" | "et" | "fr" | "ga" | "hr" | "hu" | "id" | "is" | "it" | "ku" | "la" | "lt" | "lv" | "mi" | "ms" | "mt" | "nl" | "no" | "oc" | "pi" | "pl" | "pt" | "ro" | "rs_latin" | "sk" | "sl" | "sq" | "sv" | "sw" | "tl" | "tr" | "uz" | "vi" | "ar" | "fa" | "ug" | "ur" | "bn" | "as" | "mni" | "ru" | "rs_cyrillic" | "be" | "bg" | "uk" | "mn" | "abq" | "ady" | "kbd" | "ava" | "dar" | "inh" | "che" | "lbe" | "lez" | "tab" | "tjk" | "hi" | "mr" | "ne" | "bh" | "mai" | "ang" | "bho" | "mah" | "sck" | "new" | "gom" | "sa" | "bgc" | "th" | "ch_sim" | "ch_tra" | "ja" | "ko" | "ta" | "te" | "kn";
/**
 * Enum for representing the languages supported by the parser
 */
declare const ParserLanguages: {
    readonly AF: "af";
    readonly AZ: "az";
    readonly BS: "bs";
    readonly CS: "cs";
    readonly CY: "cy";
    readonly DA: "da";
    readonly DE: "de";
    readonly EN: "en";
    readonly ES: "es";
    readonly ET: "et";
    readonly FR: "fr";
    readonly GA: "ga";
    readonly HR: "hr";
    readonly HU: "hu";
    readonly ID: "id";
    readonly IS: "is";
    readonly IT: "it";
    readonly KU: "ku";
    readonly LA: "la";
    readonly LT: "lt";
    readonly LV: "lv";
    readonly MI: "mi";
    readonly MS: "ms";
    readonly MT: "mt";
    readonly NL: "nl";
    readonly NO: "no";
    readonly OC: "oc";
    readonly PI: "pi";
    readonly PL: "pl";
    readonly PT: "pt";
    readonly RO: "ro";
    readonly RS_LATIN: "rs_latin";
    readonly SK: "sk";
    readonly SL: "sl";
    readonly SQ: "sq";
    readonly SV: "sv";
    readonly SW: "sw";
    readonly TL: "tl";
    readonly TR: "tr";
    readonly UZ: "uz";
    readonly VI: "vi";
    readonly AR: "ar";
    readonly FA: "fa";
    readonly UG: "ug";
    readonly UR: "ur";
    readonly BN: "bn";
    readonly AS: "as";
    readonly MNI: "mni";
    readonly RU: "ru";
    readonly RS_CYRILLIC: "rs_cyrillic";
    readonly BE: "be";
    readonly BG: "bg";
    readonly UK: "uk";
    readonly MN: "mn";
    readonly ABQ: "abq";
    readonly ADY: "ady";
    readonly KBD: "kbd";
    readonly AVA: "ava";
    readonly DAR: "dar";
    readonly INH: "inh";
    readonly CHE: "che";
    readonly LBE: "lbe";
    readonly LEZ: "lez";
    readonly TAB: "tab";
    readonly TJK: "tjk";
    readonly HI: "hi";
    readonly MR: "mr";
    readonly NE: "ne";
    readonly BH: "bh";
    readonly MAI: "mai";
    readonly ANG: "ang";
    readonly BHO: "bho";
    readonly MAH: "mah";
    readonly SCK: "sck";
    readonly NEW: "new";
    readonly GOM: "gom";
    readonly SA: "sa";
    readonly BGC: "bgc";
    readonly TH: "th";
    readonly CH_SIM: "ch_sim";
    readonly CH_TRA: "ch_tra";
    readonly JA: "ja";
    readonly KO: "ko";
    readonly TA: "ta";
    readonly TE: "te";
    readonly KN: "kn";
};
/**
 * Enum for representing the mode of parsing to be used
 */
type ParsingMode = "parse_page_without_llm" | "parse_page_with_llm" | "parse_page_with_lvm" | "parse_page_with_agent" | "parse_page_with_layout_agent" | "parse_document_with_llm" | "parse_document_with_lvm" | "parse_document_with_agent";
/**
 * Enum for representing the mode of parsing to be used
 */
declare const ParsingMode: {
    readonly PARSE_PAGE_WITHOUT_LLM: "parse_page_without_llm";
    readonly PARSE_PAGE_WITH_LLM: "parse_page_with_llm";
    readonly PARSE_PAGE_WITH_LVM: "parse_page_with_lvm";
    readonly PARSE_PAGE_WITH_AGENT: "parse_page_with_agent";
    readonly PARSE_PAGE_WITH_LAYOUT_AGENT: "parse_page_with_layout_agent";
    readonly PARSE_DOCUMENT_WITH_LLM: "parse_document_with_llm";
    readonly PARSE_DOCUMENT_WITH_LVM: "parse_document_with_lvm";
    readonly PARSE_DOCUMENT_WITH_AGENT: "parse_document_with_agent";
};
/**
 * Schema for a pipeline.
 */
type PipelineReadable = {
    /**
     * Unique identifier
     */
    id: string;
    /**
     * Creation datetime
     */
    created_at?: string | null;
    /**
     * Update datetime
     */
    updated_at?: string | null;
    name: string;
    project_id: string;
    /**
     * The ID of the EmbeddingModelConfig this pipeline is using.
     */
    embedding_model_config_id?: string | null;
    /**
     * The embedding model configuration for this pipeline.
     */
    embedding_model_config?: EmbeddingModelConfig | null;
    /**
     * Type of pipeline. Either PLAYGROUND or MANAGED.
     */
    pipeline_type?: PipelineType;
    /**
     * The ID of the ManagedPipeline this playground pipeline is linked to.
     */
    managed_pipeline_id?: string | null;
    embedding_config: ({
        type: "MANAGED_OPENAI_EMBEDDING";
    } & ManagedOpenAiEmbeddingConfig) | ({
        type: "AZURE_EMBEDDING";
    } & AzureOpenAiEmbeddingConfig) | ({
        type: "COHERE_EMBEDDING";
    } & CohereEmbeddingConfig) | ({
        type: "GEMINI_EMBEDDING";
    } & GeminiEmbeddingConfig) | ({
        type: "HUGGINGFACE_API_EMBEDDING";
    } & HuggingFaceInferenceApiEmbeddingConfig) | ({
        type: "OPENAI_EMBEDDING";
    } & OpenAiEmbeddingConfig) | ({
        type: "VERTEXAI_EMBEDDING";
    } & VertexAiEmbeddingConfig) | ({
        type: "BEDROCK_EMBEDDING";
    } & BedrockEmbeddingConfig);
    /**
     * Configuration for the sparse model used in hybrid search.
     */
    sparse_model_config?: SparseModelConfig | null;
    /**
     * Hashes for the configuration of the pipeline.
     */
    config_hash?: PipelineConfigurationHashes | null;
    /**
     * Configuration for the transformation.
     */
    transform_config?: AutoTransformConfig | AdvancedModeTransformConfig;
    /**
     * Preset retrieval parameters for the pipeline.
     */
    preset_retrieval_parameters?: PresetRetrievalParams;
    /**
     * Eval parameters for the pipeline.
     */
    eval_parameters?: EvalExecutionParams;
    /**
     * Settings that can be configured for how to use LlamaParse to parse files within a LlamaCloud pipeline.
     */
    llama_parse_parameters?: LlamaParseParameters | null;
    /**
     * The data sink for the pipeline. If None, the pipeline will use the fully managed data sink.
     */
    data_sink?: DataSinkReadable | null;
    /**
     * Status of the pipeline.
     */
    status?: ("CREATED" | "DELETING") | null;
    /**
     * Metadata configuration for the pipeline.
     */
    metadata_config?: PipelineMetadataConfig | null;
};
/**
 * Hashes for the configuration of a pipeline.
 */
type PipelineConfigurationHashes = {
    /**
     * Hash of the embedding config.
     */
    embedding_config_hash?: string | null;
    /**
     * Hash of the llama parse parameters.
     */
    parsing_config_hash?: string | null;
    /**
     * Hash of the transform config.
     */
    transform_config_hash?: string | null;
};
type PipelineMetadataConfig = {
    /**
     * List of metadata keys to exclude from embeddings
     */
    excluded_embed_metadata_keys?: Array<string>;
    /**
     * List of metadata keys to exclude from LLM during retrieval
     */
    excluded_llm_metadata_keys?: Array<string>;
};
/**
 * Enum for representing the type of a pipeline
 */
type PipelineType = "PLAYGROUND" | "MANAGED";
/**
 * Enum for representing the type of a pipeline
 */
declare const PipelineType: {
    readonly PLAYGROUND: "PLAYGROUND";
    readonly MANAGED: "MANAGED";
};
/**
 * Enum of possible pooling choices with pooling behaviors.
 */
type Pooling = "cls" | "mean" | "last";
/**
 * Enum of possible pooling choices with pooling behaviors.
 */
declare const Pooling: {
    readonly CLS: "cls";
    readonly MEAN: "mean";
    readonly LAST: "last";
};
/**
 * Schema for the search params for an retrieval execution that can be preset for a pipeline.
 */
type PresetRetrievalParams = {
    /**
     * Number of nodes for dense retrieval.
     */
    dense_similarity_top_k?: number | null;
    /**
     * Minimum similarity score wrt query for retrieval
     */
    dense_similarity_cutoff?: number | null;
    /**
     * Number of nodes for sparse retrieval.
     */
    sparse_similarity_top_k?: number | null;
    /**
     * Enable reranking for retrieval
     */
    enable_reranking?: boolean | null;
    /**
     * Number of reranked nodes for returning.
     */
    rerank_top_n?: number | null;
    /**
     * Alpha value for hybrid retrieval to determine the weights between dense and sparse retrieval. 0 is sparse retrieval and 1 is dense retrieval.
     */
    alpha?: number | null;
    /**
     * Search filters for retrieval.
     */
    search_filters?: MetadataFilters | null;
    /**
     * JSON Schema that will be used to infer search_filters. Omit or leave as null to skip inference.
     */
    search_filters_inference_schema?: {
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    } | null;
    /**
     * Number of files to retrieve (only for retrieval mode files_via_metadata and files_via_content).
     */
    files_top_k?: number | null;
    /**
     * The retrieval mode for the query.
     */
    retrieval_mode?: RetrievalMode;
    /**
     * Whether to retrieve image nodes.
     * @deprecated
     */
    retrieve_image_nodes?: boolean;
    /**
     * Whether to retrieve page screenshot nodes.
     */
    retrieve_page_screenshot_nodes?: boolean;
    /**
     * Whether to retrieve page figure nodes.
     */
    retrieve_page_figure_nodes?: boolean;
    class_name?: string;
};
type RetrievalMode = "chunks" | "files_via_metadata" | "files_via_content" | "auto_routed";
declare const RetrievalMode: {
    readonly CHUNKS: "chunks";
    readonly FILES_VIA_METADATA: "files_via_metadata";
    readonly FILES_VIA_CONTENT: "files_via_content";
    readonly AUTO_ROUTED: "auto_routed";
};
type SemanticChunkingConfig = {
    mode?: "semantic";
    buffer_size?: number;
    breakpoint_percentile_threshold?: number;
};
type SentenceChunkingConfig = {
    chunk_size?: number;
    chunk_overlap?: number;
    mode?: "sentence";
    separator?: string;
    paragraph_separator?: string;
};
/**
 * Configuration for sparse embedding models used in hybrid search.
 *
 * This allows users to choose between Splade and BM25 models for
 * sparse retrieval in managed data sinks.
 */
type SparseModelConfig = {
    /**
     * The sparse model type to use. 'auto' selects based on deployment mode (BYOC uses term frequency, Cloud uses Splade), 'splade' uses HuggingFace Splade model, 'bm25' uses Qdrant's FastEmbed BM25 model.
     */
    model_type?: SparseModelType;
    class_name?: string;
};
/**
 * Enum for sparse model types supported in LlamaCloud.
 *
 * SPLADE: Uses HuggingFace Splade model for sparse embeddings
 * BM25: Uses Qdrant's FastEmbed BM25 model for sparse embeddings
 * AUTO: Automatically selects based on deployment mode (BYOC uses term frequency, Cloud uses Splade)
 */
type SparseModelType = "splade" | "bm25" | "auto";
/**
 * Enum for sparse model types supported in LlamaCloud.
 *
 * SPLADE: Uses HuggingFace Splade model for sparse embeddings
 * BM25: Uses Qdrant's FastEmbed BM25 model for sparse embeddings
 * AUTO: Automatically selects based on deployment mode (BYOC uses term frequency, Cloud uses Splade)
 */
declare const SparseModelType: {
    readonly SPLADE: "splade";
    readonly BM25: "bm25";
    readonly AUTO: "auto";
};
type SupportedLlmModelNames = "GPT_4O" | "GPT_4O_MINI" | "GPT_4_1" | "GPT_4_1_NANO" | "GPT_4_1_MINI" | "AZURE_OPENAI_GPT_4O" | "AZURE_OPENAI_GPT_4O_MINI" | "AZURE_OPENAI_GPT_4_1" | "AZURE_OPENAI_GPT_4_1_MINI" | "AZURE_OPENAI_GPT_4_1_NANO" | "CLAUDE_3_5_SONNET" | "BEDROCK_CLAUDE_3_5_SONNET_V1" | "BEDROCK_CLAUDE_3_5_SONNET_V2" | "VERTEX_AI_CLAUDE_3_5_SONNET_V2";
declare const SupportedLlmModelNames: {
    readonly GPT_4O: "GPT_4O";
    readonly GPT_4O_MINI: "GPT_4O_MINI";
    readonly GPT_4_1: "GPT_4_1";
    readonly GPT_4_1_NANO: "GPT_4_1_NANO";
    readonly GPT_4_1_MINI: "GPT_4_1_MINI";
    readonly AZURE_OPENAI_GPT_4O: "AZURE_OPENAI_GPT_4O";
    readonly AZURE_OPENAI_GPT_4O_MINI: "AZURE_OPENAI_GPT_4O_MINI";
    readonly AZURE_OPENAI_GPT_4_1: "AZURE_OPENAI_GPT_4_1";
    readonly AZURE_OPENAI_GPT_4_1_MINI: "AZURE_OPENAI_GPT_4_1_MINI";
    readonly AZURE_OPENAI_GPT_4_1_NANO: "AZURE_OPENAI_GPT_4_1_NANO";
    readonly CLAUDE_3_5_SONNET: "CLAUDE_3_5_SONNET";
    readonly BEDROCK_CLAUDE_3_5_SONNET_V1: "BEDROCK_CLAUDE_3_5_SONNET_V1";
    readonly BEDROCK_CLAUDE_3_5_SONNET_V2: "BEDROCK_CLAUDE_3_5_SONNET_V2";
    readonly VERTEX_AI_CLAUDE_3_5_SONNET_V2: "VERTEX_AI_CLAUDE_3_5_SONNET_V2";
};
type TokenChunkingConfig = {
    chunk_size?: number;
    chunk_overlap?: number;
    mode?: "token";
    separator?: string;
};
type VertexAiEmbeddingConfig = {
    /**
     * Type of the embedding model.
     */
    type?: "VERTEXAI_EMBEDDING";
    /**
     * Configuration for the VertexAI embedding model.
     */
    component?: VertexTextEmbedding;
};
/**
 * Copied from llama_index.embeddings.vertex.base.VertexEmbeddingMode
 * since importing llama_index.embeddings.vertex.base incurs a lot of memory usage.
 */
type VertexEmbeddingMode = "default" | "classification" | "clustering" | "similarity" | "retrieval";
/**
 * Copied from llama_index.embeddings.vertex.base.VertexEmbeddingMode
 * since importing llama_index.embeddings.vertex.base incurs a lot of memory usage.
 */
declare const VertexEmbeddingMode: {
    readonly DEFAULT: "default";
    readonly CLASSIFICATION: "classification";
    readonly CLUSTERING: "clustering";
    readonly SIMILARITY: "similarity";
    readonly RETRIEVAL: "retrieval";
};
type VertexTextEmbedding = {
    /**
     * The modelId of the VertexAI model to use.
     */
    model_name?: string;
    /**
     * The batch size for embedding calls.
     */
    embed_batch_size?: number;
    /**
     * The number of workers to use for async embedding calls.
     */
    num_workers?: number | null;
    /**
     * The default location to use when making API calls.
     */
    location: string;
    /**
     * The default GCP project to use when making Vertex API calls.
     */
    project: string;
    /**
     * The embedding mode to use.
     */
    embed_mode?: VertexEmbeddingMode;
    /**
     * Additional kwargs for the Vertex.
     */
    additional_kwargs?: {
        [key: string]: unknown;
    };
    /**
     * The client email for the VertexAI credentials.
     */
    client_email: string | null;
    /**
     * The token URI for the VertexAI credentials.
     */
    token_uri: string | null;
    /**
     * The private key ID for the VertexAI credentials.
     */
    private_key_id: string | null;
    /**
     * The private key for the VertexAI credentials.
     */
    private_key: string | null;
    class_name?: string;
};
/**
 * Allows the user to configure webhook options for notifications and callbacks.
 */
type WebhookConfiguration = {
    /**
     * The URL to send webhook notifications to.
     */
    webhook_url?: string | null;
    /**
     * Custom HTTP headers to include with webhook requests.
     */
    webhook_headers?: {
        [key: string]: string;
    } | null;
    /**
     * List of event names to subscribe to
     */
    webhook_events?: Array<"extract.pending" | "extract.success" | "extract.error" | "extract.partial_success" | "extract.cancelled" | "parse.pending" | "parse.success" | "parse.error" | "parse.partial_success" | "parse.cancelled" | "unmapped_event"> | null;
    /**
     * The output format to use for the webhook. Defaults to string if none supplied. Currently supported values: string, json
     */
    webhook_output_format?: string | null;
};

declare class LLamaCloudFileService {
    /**
     * Get list of projects, each project contains a list of pipelines
     */
    static getAllProjectsWithPipelines(): Promise<{
        pipelines: PipelineReadable[];
        name: string;
        id: string;
        created_at?: string | null;
        updated_at?: string | null;
        ad_hoc_eval_dataset_id?: string | null;
        organization_id: string;
        is_default?: boolean;
    }[]>;
    /**
     * Upload a file to a pipeline in LlamaCloud
     */
    static addFileToPipeline(projectId: string, pipelineId: string, uploadFile: File | Blob, customMetadata?: Record<string, any>): Promise<string>;
    /**
     * Get download URL for a file in LlamaCloud
     */
    static getFileUrl(pipelineId: string, filename: string): Promise<string | null>;
}

type ClientParams = {
    apiKey?: string | undefined;
    baseUrl?: string | undefined;
};
type CloudConstructorParams = {
    name: string;
    projectName: string;
    organizationId?: string | undefined;
} & ClientParams;
type ExtractResult = {
    data: {
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    } | Array<{
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    }> | null;
    extractionMetadata: {
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    };
};

type CloudRetrieveParams = Omit<RetrievalParams, "query" | "search_filters" | "dense_similarity_top_k"> & {
    similarityTopK?: number;
    filters?: MetadataFilters$1;
};
declare class LlamaCloudRetriever extends BaseRetriever {
    clientParams: ClientParams;
    retrieveParams: CloudRetrieveParams;
    organizationId?: string;
    projectName: string;
    pipelineName: string;
    private resultNodesToNodeWithScore;
    private fetchBase64FromPresignedUrl;
    private pageScreenshotNodesToNodeWithScore;
    private pageFigureNodesToNodeWithScore;
    private convertFilter;
    constructor(params: CloudConstructorParams & CloudRetrieveParams);
    _retrieve(query: QueryBundle): Promise<NodeWithScore[]>;
}

type QueryToolParams = {
    metadata?: Omit<ToolMetadata, "parameters"> | undefined;
    includeSourceNodes?: boolean;
};

type QueryEngineParams = {
    responseSynthesizer?: BaseSynthesizer;
    preFilters?: unknown;
    nodePostprocessors?: BaseNodePostprocessor[];
} & CloudRetrieveParams;
declare class LlamaCloudIndex {
    params: CloudConstructorParams;
    constructor(params: CloudConstructorParams);
    private waitForPipelineIngestion;
    private waitForDocumentIngestion;
    getPipelineId(name?: string, projectName?: string, organizationId?: string): Promise<string>;
    getProjectId(projectName?: string, organizationId?: string): Promise<string>;
    /**
     * Adds documents to the given index parameters. If the index does not exist, it will be created.
     *
     * @param params - An object containing the following properties:
     *   - documents: An array of Document objects to be added to the index.
     *   - verbose: Optional boolean to enable verbose logging.
     *   - Additional properties from CloudConstructorParams.
     * @returns A Promise that resolves to a new LlamaCloudIndex instance.
     */
    static fromDocuments(params: {
        documents: Document[];
        verbose?: boolean;
    } & CloudConstructorParams, config?: {
        embedding: PipelineCreateReadable["embedding_config"];
        transform: PipelineCreateReadable["transform_config"];
    }): Promise<LlamaCloudIndex>;
    addDocuments(documents: Document[], verbose?: boolean): Promise<void>;
    asRetriever(params?: CloudRetrieveParams): BaseRetriever;
    asQueryEngine(params?: QueryEngineParams): BaseQueryEngine;
    asQueryTool(params: QueryEngineParams & QueryToolParams): BaseTool;
    queryTool(params: QueryEngineParams & QueryToolParams): BaseTool<any>;
    insert(document: Document): Promise<void>;
    delete(document: Document): Promise<void>;
    refreshDoc(document: Document): Promise<void>;
    ensureIndex(config?: {
        embedding?: PipelineCreateReadable["embedding_config"];
        transform?: PipelineCreateReadable["transform_config"];
        verbose?: boolean;
    }): Promise<void>;
}

declare class LlamaExtractAgent {
    private agent;
    private client;
    id: string;
    name: string;
    dataSchema: {
        [key: string]: string | number | boolean | {
            [key: string]: unknown;
        } | unknown[] | null;
    };
    constructor(agent: ExtractAgent, client: Client);
    extract(filePath?: string | undefined, fileContent?: Buffer<ArrayBufferLike> | Uint8Array<ArrayBuffer> | string | File$1 | undefined, fileName?: string | undefined, project_id?: string | null, organization_id?: string | null, fromUi?: boolean | undefined, pollingInterval?: number, maxPollingIterations?: number, maxRetriesOnError?: number, retryInterval?: number): Promise<ExtractResult | undefined>;
}
declare class LlamaExtract {
    private client;
    constructor(apiKey?: string | undefined, baseUrl?: string | undefined, region?: string | undefined);
    createAgent(name: string, dataSchema: {
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    } | string, config?: ExtractConfig | undefined, project_id?: string | null, organization_id?: string | null, maxRetriesOnError?: number, retryInterval?: number): Promise<LlamaExtractAgent | undefined>;
    getAgent(name?: string | undefined, id?: string | undefined, project_id?: string | null, organization_id?: string | null, maxRetriesOnError?: number, retryInterval?: number): Promise<LlamaExtractAgent | undefined>;
    deleteAgent(id: string, maxRetriesOnError?: number, retryInterval?: number): Promise<boolean | undefined>;
    extract(dataSchema: {
        [key: string]: {
            [key: string]: unknown;
        } | Array<unknown> | string | number | number | boolean | null;
    } | string, config?: ExtractConfig | undefined, filePath?: string | undefined, fileContent?: Buffer<ArrayBufferLike> | Uint8Array<ArrayBuffer> | string | File$1 | undefined, fileName?: string | undefined, project_id?: string | null, organization_id?: string | null, pollingInterval?: number, maxPollingIterations?: number, maxRetriesOnError?: number, retryInterval?: number): Promise<ExtractResult | undefined>;
}

declare class LlamaClassify {
    private client;
    constructor(apiKey?: string | undefined, baseUrl?: string | undefined, region?: string | undefined);
    classify(rules: ClassifierRule[], parsingConfiguration: ClassifyParsingConfiguration, fileContents?: Buffer<ArrayBufferLike>[] | File$1[] | Uint8Array<ArrayBuffer>[] | string[] | undefined, filePaths?: string[] | undefined, projectId?: string | null, organizationId?: string | null, pollingInterval?: number, maxPollingIterations?: number, maxRetriesOnError?: number, retryInterval?: number): Promise<ClassifyJobResults>;
}

export { LLamaCloudFileService, LlamaClassify, LlamaCloudIndex, LlamaCloudRetriever, LlamaExtract, LlamaExtractAgent };
export type { CloudConstructorParams, CloudRetrieveParams };
